# Quick Dataset Analyzer

A minimal, end-to-end data analytics project demonstrating CSV upload, data analysis, and deployment to Azure. Built with Python, Pandas, and Streamlit, it follows professional practices: testing, version control, documentation, and containerization.

---

## ğŸš€ Project Goal
- Upload a CSV dataset with automatic encoding detection.
- Perform validation (file size, format, encoding).
- Compute comprehensive summary statistics:
  - **Numerical columns**: mean, median, standard deviation
  - **Categorical columns**: top 5 most frequent values
  - **All columns**: null value counts and data types
- **Generate interactive data visualizations**:
  - Correlation heatmaps for variable relationships
  - Histograms and boxplots for distribution analysis
  - Per-column detailed visualizations
- Provide a user-friendly Streamlit interface for data exploration and visualization.
- Deploy to Azure cloud for easy sharing and demonstration.

---

## ğŸ“‚ Project Structure

quick-dataset-analyzer/
â”‚
â”œâ”€â”€ README.md # Project overview and documentation
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ LICENSE # MIT License
â”œâ”€â”€ .gitignore # Git ignore rules
â”œâ”€â”€ src/ # Source code
â”‚ â”œâ”€â”€ app.py # Streamlit web application
â”‚ â””â”€â”€ data_pipeline.py # Data loading, validation, and statistics
â”œâ”€â”€ tests/ # Unit tests
â”‚ â””â”€â”€ test_pipeline.py # Comprehensive test suite
â”œâ”€â”€ docs/ # Documentation
â”‚ â””â”€â”€ ProjectCharter.md # PRINCE2 project charter
â””â”€â”€ data/ # Sample data directory (gitignored)

---

## âœ¨ Features

- **CSV Upload**: Support for CSV files with automatic encoding detection
- **Configurable File Size**: Environment-based file size limits (default 5MB)
- **Data Validation**: Format validation, encoding detection, and error handling
- **Summary Statistics**:
  - Numerical columns: mean, median, standard deviation
  - Categorical columns: top 5 value frequencies
  - All columns: null counts and data type information
- **Data Visualizations**:
  - **Correlation Heatmap**: Shows relationships between all numerical variables
  - **Interactive Histograms**: Distribution plots for individual numerical columns
  - **Boxplots**: Statistical summary plots with quartiles and outlier detection
  - **Per-Column Analysis**: Select specific columns for detailed visualization
- **Interactive UI**: Clean Streamlit interface with expandable sections and dynamic visualizations
- **Comprehensive Testing**: Unit tests covering all functionality
- **Cloud Ready**: Optimized for containerized deployment with configurable limits

## âš™ï¸ Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/davy-benoot/quick-dataset-analyzer.git
   cd quick-dataset-analyzer
   ```

2. Create a virtual environment:
   ```bash
   python3 -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

4. (Optional) Configure file size limit:
   ```bash
   export MAX_FILE_SIZE_MB=10  # Set to 10MB instead of default 5MB
   ```

5. Run the application:
   ```bash
   streamlit run src/app.py
   ```

## â˜ï¸ Deployment

The app is containerized with Docker.

Can be deployed to Azure App Service or any container-supported cloud service.

## ğŸ“„ Documentation

/docs/ProjectCharter.md â€” Prince2-style project charter

/docs/Architecture.md â€” System design overview

/docs/Usage.md â€” Instructions for users

## ğŸ’¡ Notes

Streamlit was chosen for rapid prototyping of a user-facing analytics dashboard.

For production-grade applications, Flask or FastAPI could be implemented.

This project demonstrates end-to-end delivery including CI/CD readiness, testing, and documentation.

## ğŸ“ License

MIT License
